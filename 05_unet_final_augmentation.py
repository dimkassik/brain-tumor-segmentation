# -*- coding: utf-8 -*-
"""05_unet_final_augmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t7pT3z68RepH5j_QdK6P_uzqjZ8-wy6X
"""

import os
import random
import numpy as np
import cv2
import pandas as pd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import tensorflow as tf

from tensorflow.keras import Input, Model
from tensorflow.keras.layers import (
    Conv2D, MaxPooling2D, Conv2DTranspose,
    Concatenate, BatchNormalization, Dropout
)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import (
    EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
)
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

# ============================================================
# CONFIG
# ============================================================
IMG_SIZE = 128
EPOCHS = 80
BATCH_SIZE = 16
LR = 1e-3

DATASET_PATH = "kaggle_3m"

MODEL_TAG = "Augmentation_UNet_LR1e-3_BS16"
MODEL_NAME = f"{MODEL_TAG}.keras"
HISTORY_CSV = f"history_{MODEL_TAG}.csv"
PRED_DIR = f"predictions_{MODEL_TAG}"

os.makedirs(PRED_DIR, exist_ok=True)

# ============================================================
# METRICS & LOSSES
# ============================================================
def dice_coef(y_true, y_pred, smooth=1e-6):
    y_pred = tf.cast(y_pred > 0.5, tf.float32)
    intersection = tf.reduce_sum(y_true * y_pred)
    return (2. * intersection + smooth) / (
        tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth
    )

def iou_coef(y_true, y_pred, smooth=1e-6):
    y_pred = tf.cast(y_pred > 0.5, tf.float32)
    intersection = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection
    return (intersection + smooth) / (union + smooth)

def dice_loss(y_true, y_pred):
    return 1 - dice_coef(y_true, y_pred)

def bce_dice_loss(y_true, y_pred):
    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)
    return bce + dice_loss(y_true, y_pred)

# ============================================================
# LOAD DATA
# ============================================================
def load_data(dataset_path, img_size=IMG_SIZE):
    images, masks = [], []

    for folder in os.listdir(dataset_path):
        folder_path = os.path.join(dataset_path, folder)
        if not os.path.isdir(folder_path):
            continue

        for file in os.listdir(folder_path):
            if file.endswith(".tif") and "mask" not in file:
                img_path = os.path.join(folder_path, file)
                mask_path = img_path.replace(".tif", "_mask.tif")
                if not os.path.exists(mask_path):
                    continue

                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                img = cv2.resize(img, (img_size, img_size)) / 255.0
                img = img[..., np.newaxis]

                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                mask = cv2.resize(mask, (img_size, img_size))
                mask = (mask > 127).astype(np.float32)
                mask = mask[..., np.newaxis]

                images.append(img)
                masks.append(mask)

    return np.array(images, dtype=np.float32), np.array(masks, dtype=np.float32)

print("ðŸ“¥ Loading dataset...")
X, y = load_data(DATASET_PATH)
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.1, random_state=42
)

print(f"Train: {X_train.shape}, Val: {X_val.shape}")

# ============================================================
# DATA AUGMENTATION
# ============================================================
def create_augmented_generator(X, y, batch_size=16, seed=42):
    img_gen = ImageDataGenerator(
        rotation_range=10,
        width_shift_range=0.05,
        height_shift_range=0.05,
        shear_range=0.05,
        zoom_range=0.1,
        horizontal_flip=True,
        vertical_flip=True,
        fill_mode="nearest"
    )

    mask_gen = ImageDataGenerator(
        rotation_range=10,
        width_shift_range=0.05,
        height_shift_range=0.05,
        shear_range=0.05,
        zoom_range=0.1,
        horizontal_flip=True,
        vertical_flip=True,
        fill_mode="nearest"
    )

    img_flow = img_gen.flow(X, batch_size=batch_size, seed=seed)
    mask_flow = mask_gen.flow(y, batch_size=batch_size, seed=seed)

    while True:
        yield next(img_flow), next(mask_flow)

train_gen = create_augmented_generator(X_train, y_train, BATCH_SIZE)
steps_per_epoch = len(X_train) // BATCH_SIZE

# ============================================================
# MODEL
# ============================================================
def unet_aug(input_size=(IMG_SIZE, IMG_SIZE, 1)):
    inputs = Input(input_size)

    c1 = Conv2D(32, 3, activation="relu", padding="same")(inputs)
    c1 = BatchNormalization()(c1)
    c1 = Conv2D(32, 3, activation="relu", padding="same")(c1)
    p1 = MaxPooling2D()(c1)

    c2 = Conv2D(64, 3, activation="relu", padding="same")(p1)
    c2 = BatchNormalization()(c2)
    c2 = Conv2D(64, 3, activation="relu", padding="same")(c2)
    p2 = MaxPooling2D()(c2)

    c3 = Conv2D(128, 3, activation="relu", padding="same")(p2)
    c3 = BatchNormalization()(c3)
    c3 = Conv2D(128, 3, activation="relu", padding="same")(c3)

    u2 = Conv2DTranspose(64, 2, strides=2, padding="same")(c3)
    u2 = Concatenate()([u2, c2])
    c4 = Conv2D(64, 3, activation="relu", padding="same")(u2)
    c4 = BatchNormalization()(c4)
    c4 = Conv2D(64, 3, activation="relu", padding="same")(c4)

    u3 = Conv2DTranspose(32, 2, strides=2, padding="same")(c4)
    u3 = Concatenate()([u3, c1])
    c5 = Conv2D(32, 3, activation="relu", padding="same")(u3)
    c5 = BatchNormalization()(c5)
    c5 = Dropout(0.1)(c5)

    outputs = Conv2D(1, 1, activation="sigmoid")(c5)
    return Model(inputs, outputs)

model = unet_aug()
model.compile(
    optimizer=Adam(LR),
    loss=bce_dice_loss,
    metrics=[dice_coef, iou_coef]
)

model.summary()

# ============================================================
# CALLBACKS
# ============================================================
callbacks = [
    EarlyStopping(
        monitor="val_dice_coef",
        patience=20,
        mode="max",
        restore_best_weights=True
    ),
    ReduceLROnPlateau(
        monitor="val_loss",
        factor=0.5,
        patience=8,
        min_lr=1e-6
    ),
    ModelCheckpoint(
        MODEL_NAME,
        monitor="val_dice_coef",
        mode="max",
        save_best_only=True
    )
]

# ============================================================
# TRAIN
# ============================================================
history = model.fit(
    train_gen,
    validation_data=(X_val, y_val),
    steps_per_epoch=steps_per_epoch,
    epochs=EPOCHS,
    callbacks=callbacks,
    verbose=1
)

# ============================================================
# SAVE HISTORY
# ============================================================
pd.DataFrame(history.history).to_csv(HISTORY_CSV, index=False)
print("ðŸ“Š History saved:", HISTORY_CSV)

# ============================================================
# PLOTS
# ============================================================
def plot_metric(metric):
    plt.figure(figsize=(8,4))
    plt.plot(history.history[metric], label=f"Train {metric}")
    plt.plot(history.history[f"val_{metric}"], label=f"Val {metric}")
    plt.title(f"{metric} per Epoch\n{MODEL_TAG}")
    plt.xlabel("Epoch")
    plt.ylabel(metric)
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.savefig(f"{metric}_{MODEL_TAG}.png")
    plt.close()

plot_metric("dice_coef")
plot_metric("iou_coef")
plot_metric("loss")

# ============================================================
# PREDICTIONS
# ============================================================
for i in random.sample(range(len(X_val)), 5):
    pred = model.predict(X_val[i:i+1])[0]

    plt.figure(figsize=(12,4))
    plt.subplot(1,3,1)
    plt.imshow(X_val[i,:,:,0], cmap="gray")
    plt.title("Input")
    plt.axis("off")

    plt.subplot(1,3,2)
    plt.imshow(y_val[i,:,:,0], cmap="gray")
    plt.title("Ground Truth")
    plt.axis("off")

    plt.subplot(1,3,3)
    plt.imshow(pred[:,:,0] > 0.5, cmap="gray")
    plt.title("Prediction")
    plt.axis("off")

    plt.savefig(os.path.join(PRED_DIR, f"prediction_{i}.png"))
    plt.close()

print("âœ… Training finished. Best model saved as:", MODEL_NAME)