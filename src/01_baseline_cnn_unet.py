# -*- coding: utf-8 -*-
"""01_baseline_cnn_unet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t7pT3z68RepH5j_QdK6P_uzqjZ8-wy6X
"""

import os
import numpy as np
import cv2
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Concatenate, UpSampling2D
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import random

# ---------------------------
# Настройки
# ---------------------------
IMG_SIZE = 128
EPOCHS = 20
DATASET_PATH = "kaggle_3m"  # путь к датасету
LR_LIST = [1e-3, 1e-4]
BATCH_LIST = [16, 32]

# ---------------------------
# Метрики Dice и IoU
# ---------------------------
def dice_coef(y_true, y_pred, smooth=1e-6):
    y_pred = tf.cast(y_pred > 0.5, tf.float32)
    intersection = tf.reduce_sum(y_true * y_pred)
    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)

def iou_coef(y_true, y_pred, smooth=1e-6):
    y_pred = tf.cast(y_pred > 0.5, tf.float32)
    intersection = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection
    return (intersection + smooth) / (union + smooth)

def dice_loss(y_true, y_pred):
    smooth = 1e-6
    intersection = tf.reduce_sum(y_true * y_pred)
    return 1 - (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)

def bce_dice_loss(y_true, y_pred):
    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)
    return bce + dice_loss(y_true, y_pred)

# ---------------------------
# Загрузка данных
# ---------------------------
def load_data(dataset_path, img_size=IMG_SIZE):
    images, masks = [], []
    patient_folders = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if
                       os.path.isdir(os.path.join(dataset_path, f))]
    for folder in patient_folders:
        img_files = [f for f in os.listdir(folder) if f.endswith(".tif") and "mask" not in f]
        for img_file in img_files:
            mask_file = img_file.replace(".tif", "_mask.tif")
            img_path, mask_path = os.path.join(folder, img_file), os.path.join(folder, mask_file)
            if not os.path.exists(mask_path):
                continue
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            img = cv2.resize(img, (img_size, img_size)).astype(np.float32) / 255.0
            img = np.expand_dims(img, axis=-1)
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            mask = cv2.resize(mask, (img_size, img_size))
            mask = (mask > 127).astype(np.float32)
            mask = np.expand_dims(mask, axis=-1)
            images.append(img)
            masks.append(mask)
    images, masks = np.array(images), np.array(masks)
    print(f"Loaded dataset: {images.shape}, {masks.shape}")
    return images, masks

print("Loading dataset...")
X, y = load_data(DATASET_PATH)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)

# ---------------------------
# Модели
# ---------------------------
def unet(input_size=(IMG_SIZE, IMG_SIZE, 1)):
    inputs = Input(input_size)
    c1 = Conv2D(16, 3, activation='relu', padding='same')(inputs)
    c1 = Conv2D(16, 3, activation='relu', padding='same')(c1)
    p1 = MaxPooling2D(2)(c1)
    c2 = Conv2D(32, 3, activation='relu', padding='same')(p1)
    c2 = Conv2D(32, 3, activation='relu', padding='same')(c2)
    p2 = MaxPooling2D(2)(c2)
    c3 = Conv2D(64, 3, activation='relu', padding='same')(p2)
    c3 = Conv2D(64, 3, activation='relu', padding='same')(c3)
    u2 = Conv2DTranspose(32, 2, strides=2, padding='same')(c3)
    u2 = Concatenate()([u2, c2])
    c4 = Conv2D(32, 3, activation='relu', padding='same')(u2)
    c4 = Conv2D(32, 3, activation='relu', padding='same')(c4)
    u3 = Conv2DTranspose(16, 2, strides=2, padding='same')(c4)
    u3 = Concatenate()([u3, c1])
    c5 = Conv2D(16, 3, activation='relu', padding='same')(u3)
    outputs = Conv2D(1, 1, activation='sigmoid')(c5)
    return Model(inputs=inputs, outputs=outputs)


def simple_cnn(input_size=(IMG_SIZE, IMG_SIZE, 1)):
    inputs = Input(input_size)
    c1 = Conv2D(16, 3, activation='relu', padding='same')(inputs)
    c2 = Conv2D(32, 3, activation='relu', padding='same')(c1)
    c3 = Conv2D(64, 3, activation='relu', padding='same')(c2)
    # Один Upsampling: 128x128 -> 128x128 (не меняем размер, т.к. padding same)
    # Если хочешь добавить, можно использовать Conv2DTranspose для обучения
    c4 = Conv2D(32, 3, activation='relu', padding='same')(c3)
    c5 = Conv2D(16, 3, activation='relu', padding='same')(c4)
    outputs = Conv2D(1, 1, activation='sigmoid')(c5)
    return Model(inputs=inputs, outputs=outputs)



# ---------------------------
# Обучение с перебором гиперпараметров
# ---------------------------
results = []

for model_name, model_func in [("U-Net", unet), ("SimpleCNN", simple_cnn)]:
    for lr in LR_LIST:
        for batch_size in BATCH_LIST:
            save_path = f"{model_name}_LR{lr}_BS{batch_size}.keras"
            if os.path.exists(save_path):
                print(f"Model {save_path} already exists, skipping training.")
                continue

            print(f"\nTraining {model_name} with LR={lr}, Batch={batch_size}")

            # Очистка предыдущей модели/графа
            tf.keras.backend.clear_session()

            model = model_func()
            model.compile(optimizer=Adam(lr), loss=bce_dice_loss, metrics=[dice_coef, iou_coef])
            history = model.fit(
                X_train, y_train,
                validation_data=(X_val, y_val),
                epochs=EPOCHS,
                batch_size=batch_size,
                verbose=1
            )

            # Сохраняем модель
            model.save(save_path)
            print(f"Saved model to {save_path}")

            # Сохраняем историю метрик
            results.append({
                "model": model_name,
                "lr": lr,
                "batch_size": batch_size,
                "history": history.history
            })

            # Визуализация предсказания
            idx = random.randint(0, len(X_val) - 1)
            sample_img, sample_mask = X_val[idx], y_val[idx]
            pred_mask = model.predict(np.expand_dims(sample_img, axis=0))[0]

            plt.figure(figsize=(12, 4))
            plt.subplot(1, 3, 1)
            plt.title("Input Image")
            plt.imshow(sample_img[:, :, 0], cmap='gray')
            plt.axis('off')

            plt.subplot(1, 3, 2)
            plt.title("True Mask")
            plt.imshow(sample_mask[:, :, 0], cmap='gray')
            plt.axis('off')

            plt.subplot(1, 3, 3)
            plt.title("Predicted Mask")
            plt.imshow(pred_mask[:, :, 0] > 0.5, cmap='gray')
            plt.axis('off')

            plt.tight_layout()
            pred_file = f"{model_name}_LR{lr}_BS{batch_size}_prediction.png"
            plt.savefig(pred_file)
            plt.close()
            print(f"Saved prediction visualization to {pred_file}")

# ---------------------------
# Визуализация метрик Dice/IoU
# ---------------------------
for res in results:
    plt.figure(figsize=(10, 4))
    plt.plot(res['history']['dice_coef'], label='Train Dice')
    plt.plot(res['history']['val_dice_coef'], label='Val Dice')
    plt.title(f"{res['model']} LR={res['lr']} BS={res['batch_size']} - Dice")
    plt.xlabel("Epochs")
    plt.ylabel("Dice Coefficient")
    plt.legend()
    plt.savefig(f"{res['model']}_LR{res['lr']}_BS{res['batch_size']}_dice.png")
    plt.close()

    plt.figure(figsize=(10, 4))
    plt.plot(res['history']['iou_coef'], label='Train IoU')
    plt.plot(res['history']['val_iou_coef'], label='Val IoU')
    plt.title(f"{res['model']} LR={res['lr']} BS={res['batch_size']} - IoU")
    plt.xlabel("Epochs")
    plt.ylabel("IoU Coefficient")
    plt.legend()
    plt.savefig(f"{res['model']}_LR{res['lr']}_BS{res['batch_size']}_iou.png")
    plt.close()